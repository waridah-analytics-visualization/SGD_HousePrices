# SGD_HousePrices

California Housing Price Prediction: SGD Regressor AnalysisProject OverviewThis project implements a Machine Learning pipeline to predict house prices in California using the Scikit-learn California Housing dataset (20,640 samples). The initial model uses a Stochastic Gradient Descent (SGD) Regressor, a linear approach optimized for large-scale datasets.Current ImplementationThe pipeline includes the following key stages:Data Partitioning: 80/20 Train-Test split.Feature Scaling: Application of StandardScaler to ensure features have a mean of 0 and variance of 1 (essential for gradient descent convergence).Modeling: Implementation of SGDRegressor with squared loss.Visualization: Comparison of actual vs. predicted prices with a \(y=x\) reference line.Key ObservationsPerformance Metrics:Mean Squared Error (MSE): 0.5506RÂ² Score: 0.5798 (The model explains ~58% of the price variance).Error Analysis: The scatter plot shows a significant "cloud" of points around the identity line, indicating moderate prediction error (approx. $74,200 on average).Data Constraints: A visible horizontal "ceiling" at 5.0 ($500,000) indicates capped data values, which limits the model's accuracy for high-end luxury properties.Next Steps: Strategies for ImprovementTo move the \(R^{2}\) score closer to 1.0, we will execute two distinct strategies:Action 1: Complexity Enhancement (Stay with SGD)The current SGD model is purely linear, meaning it assumes that if a feature (like income) doubles, the price change is constant. In reality, housing data is complex and non-linear.The Plan: Introduce Polynomial Features (interaction terms).Goal: By transforming features into squares or combinations (e.g., \(Income\times Rooms\)), we allow the SGD model to "see" curves in the data, potentially capturing geographic "hotspots" or diminishing returns on house size.Action 2: Architectural Shift (Random Forest Regressor)Linear models often struggle with the California dataset because location (Latitude/Longitude) affects price in clusters, not straight lines.The Plan: Switch to a Random Forest Regressor, an ensemble of Decision Trees.Goal: Random Forests do not assume a linear relationship and are excellent at capturing non-linear patterns and interactions automatically. This usually results in a significantly higher \(R^{2}\) score (often > 0.80) for this specific dataset.


